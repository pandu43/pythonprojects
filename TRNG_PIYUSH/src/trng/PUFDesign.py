#
# import os
# import math
# import gc
# import pandas as pd
# import numpy as np
# from multiprocessing import Pool, cpu_count
# from functools import partial
# from datetime import datetime
#
# class PUFDesign:
#     def __init__(self, crp_bit, file_path, usecols, skiprows=None):
#         self.file_path = file_path
#         self.usecols = usecols
#         self.skiprows = skiprows if skiprows is not None else []
#         self.chr = crp_bit
#         # Faster file loading (no dtype guessing)
#         file_extension = os.path.splitext(self.file_path)[1].lower()
#         if file_extension in ['.xlsx', '.xls']:
#             df = pd.read_excel(self.file_path, usecols=self.usecols, skiprows=self.skiprows, engine='openpyxl')
#         elif file_extension == '.csv':
#             df = pd.read_csv(self.file_path, usecols=self.usecols, skiprows=self.skiprows, dtype=np.float32)
#         else:
#             raise ValueError("Unsupported file type. Please use an Excel or CSV file.")
#         self.data = df.values.flatten()
#         # random shuffle data
#         np.random.shuffle(self.data)
#         self.data_len = len(self.data)
#         print(f"Total number of resistance data points: {self.data_len}")
#         del df
#         gc.collect()
#
#     def shuffle_and_resize(self, arr, new_length):
#         if new_length > len(arr):
#             raise ValueError("new_length exceeds available data size.")
#         return np.random.choice(arr, size=new_length, replace=False)
#
#     @staticmethod
#     def row_col_bit(a):
#         b = math.log2(a)
#         x = (b + a) / 2
#         y = a - x
#         return round(x), round(y)
#
#     @staticmethod
#     def get_response(rram_cell_1, rram_cell_2):
#         return (rram_cell_1 > rram_cell_2).astype(np.uint8)
#
#     @staticmethod
#     def converts_decimal(count, arr):
#         arr = np.asarray(arr, dtype=np.uint8)
#         powers = (1 << np.arange(len(arr)-1, -1, -1, dtype=np.uint64))
#         return int(np.dot(arr, powers))
#
#     def process_challenge_batch(self, batch_indices, challenge_len, select_line):
#         """Process a batch of challenges (vectorized and clean output)."""
#         results = []
#         data = self.data
#         for i in batch_indices:
#             # np.random.seed(i)
#             a1 = np.random.choice(data, challenge_len, replace=False)
#
#             # a2 = np.random.choice(data, challenge_len, replace=False)
#             # remove a1 elements from data so a2 gets different values
#             remaining = np.setdiff1d(data, a1)
#             a2 = np.random.choice(remaining, challenge_len, replace=False)
#
#             challenge_bits = np.array(list(map(int, np.binary_repr(i, width=challenge_len))), dtype=np.uint8)
#             response_bits = self.get_response(a1, a2)
#             challenge_str = ''.join(map(str, challenge_bits.tolist()))
#             response_str = ''.join(map(str, response_bits.tolist()))
#             c_dec = self.converts_decimal(challenge_len - 1, challenge_bits)
#             r_dec = self.converts_decimal(challenge_len - 1, response_bits)
#             results.append((challenge_str, response_str, c_dec, r_dec))
#         return results
#
#     def challenge_response_diff(self, crp, challenge_len, file_name, save_csv=True, Binary=True, timestamp="", run_idx=None):
#         row, col = self.row_col_bit(challenge_len)
#         select_line = row
#         num_workers = min(cpu_count(), 8)
#         print(f"Using {num_workers} CPU cores...")
#         # Ensure timestamp is provided (generated by main_HRS)
#         if not timestamp:
#             timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
#         folder_name = f"{timestamp}_C{challenge_len}R{crp}"
#         base_dir = os.path.dirname(file_name)
#         base_filename = os.path.basename(file_name)
#         timestamp_dir = os.path.join(base_dir, folder_name)
#         csv_dir = os.path.join(timestamp_dir, 'CSV')
#         txt_dir = os.path.join(timestamp_dir, 'txt')
#         os.makedirs(csv_dir, exist_ok=True)
#         os.makedirs(txt_dir, exist_ok=True)
#
#         print("\n")
#         print("\n[SAVE INFO]")
#         print("Base file name      :", base_filename)
#         print("\nBase directory      :", os.path.abspath(base_dir))
#         print("\nTimestamp directory :", os.path.abspath(timestamp_dir))
#         print("\nCSV save directory  :", os.path.abspath(csv_dir))
#         print("\nTXT save directory  :", os.path.abspath(txt_dir))
#
#         # print("\n[END SAVE INFO]\n")
#         print("\n**********************************************************************************")
#         print("\n                           [PUF RESULT]")
#         print("\n                          [END SAVE INFO]")
#         print("\n**********************************************************************************\n\n")
#         total_challenges = 2 ** crp
#         batch_size = 262200 #200000
#         num_batches = (total_challenges + batch_size - 1) // batch_size
#         with Pool(processes=num_workers) as pool:
#             for batch_idx in range(num_batches):
#                 start = batch_idx * batch_size
#                 end = min((batch_idx + 1) * batch_size, total_challenges)
#                 if start >= total_challenges:
#                     break
#                 print(f"Processing batch {batch_idx+1}/{num_batches} ({start}â€“{end-1})")
#                 indices = np.array_split(np.arange(start, end), num_workers)
#                 func = partial(self.process_challenge_batch, challenge_len=challenge_len, select_line=select_line)
#                 results = pool.map(func, indices)
#                 results = [r for sub in results for r in sub]
#                 challenges_bin, responses_bin, challenges, responses = zip(*results)
#                 # Incorporate run index into filenames if provided
#                 run_suffix = f"_run{run_idx}" if run_idx is not None else ""
#                 csv_file = os.path.join(csv_dir, f'{base_filename}_C{challenge_len}R{crp}_batch{batch_idx}{run_suffix}.csv')
#                 txt_file = os.path.join(txt_dir, f'{base_filename}_C{challenge_len}R{crp}_batch{batch_idx}{run_suffix}.txt')
#                 if save_csv:
#                     pd.DataFrame({
#                         f'Challenges_{challenge_len}': challenges_bin,
#                         f'ResponsesBinary_{challenge_len}': responses_bin,
#                         'ChallengeDecimal': challenges,
#                         'ResponseDecimal': responses
#                     }).to_csv(csv_file, index=False)
#                 if Binary:
#                     with open(txt_file, 'w') as f:
#                         f.write(''.join(responses_bin))
#                 print(f"Saved batch {batch_idx+1}{run_suffix}")
#                 del results
#                 gc.collect()
#
# def main_HRS(challenge_size, crp, save_csv=True, Binary=True, runs=10, timestamp="",project_root=None):
#     """Run the PUF design and Shannon entropy pipeline multiple times.
#     A single timestamp is generated for the whole series of runs.
#     Each run's output files embed the run index in their names.
#     """
#     # Generate a single timestamp for all runs if not provided
#     base_timestamp = timestamp if timestamp else datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
#     BASE_DIR = os.path.dirname(os.path.abspath(__file__))
#
#     input_file = os.path.join(
#         BASE_DIR,
#         '..', '..', '..',  # adjust if needed
#         'TRNG_PIYUSH',
#         'RRAM_1M_data',
#         '1.9V-1us 1million data.csv'
#     )
#
#     # ðŸ”´ PRINT INPUT FILE LOCATION
#     print("\n[PATH INFO]")
#     print("\nPUFDesign file      :", os.path.abspath(__file__))
#     print("\nInput CSV file      :", os.path.abspath(input_file))
#     print("\nInput file exists   :", os.path.exists(input_file))
#
#     print("\n")
#
#     puf = PUFDesign(crp, input_file, usecols=[1], skiprows=[0])
#     # file_name = os.path.join('TRNG_PIYUSH/Result', 'TRAN_result', "TRNG_bitstream_data")
#
#     file_name = os.path.join(
#         BASE_DIR,
#         '..', '..', '..',  # go from src/trng â†’ TRNG_PIYUSH
#         'TRNG_PIYUSH',
#         'Result',
#         'TRAN_result',
#         'TRNG_bitstream_data'
#     )
#     file_name = os.path.abspath(file_name)
#
#     for run_idx in range(runs):
#         print(f"[HARN] Run {run_idx+1}/{runs} with base timestamp {base_timestamp}")
#         # Pass the run index to embed in filenames
#         puf.challenge_response_diff(crp, challenge_size, file_name,
#                                    save_csv=save_csv, Binary=Binary,
#                                    timestamp=base_timestamp, run_idx=run_idx)
#
#
# if __name__ == "__main__":
#     try:
#         c_str = input("Enter challenge size (default 16): ").strip()
#         challenge_size = int(c_str) if c_str else 16
#
#         crp_str = input("Enter crp (default 8): ").strip()
#         crp = int(crp_str) if crp_str else 8
#
#         print(f"[INFO] Starting main_HRS with C={challenge_size}, R={crp}")
#         main_HRS(challenge_size, crp, save_csv=True, Binary=True, runs=2)
#     except EOFError:
#         print("\n[INFO] Non-interactive environment detected. Using defaults: C=16, R=8")
#         main_HRS(16, 8, save_csv=True, Binary=True, runs=2)
#     except Exception as e:
#         print(f"[ERROR] Execution failed: {e}")


import os
import math
import gc
import pandas as pd
import numpy as np
from multiprocessing import Pool, cpu_count
from functools import partial
from datetime import datetime


class PUFDesign:
    def __init__(self, crp_bit, file_path, usecols, skiprows=None):
        self.file_path = file_path
        self.usecols = usecols
        self.skiprows = skiprows if skiprows is not None else []
        self.chr = crp_bit

        file_extension = os.path.splitext(self.file_path)[1].lower()
        if file_extension in ['.xlsx', '.xls']:
            df = pd.read_excel(
                self.file_path,
                usecols=self.usecols,
                skiprows=self.skiprows,
                engine='openpyxl'
            )
        elif file_extension == '.csv':
            df = pd.read_csv(
                self.file_path,
                usecols=self.usecols,
                skiprows=self.skiprows,
                dtype=np.float32
            )
        else:
            raise ValueError("Unsupported file type. Please use Excel or CSV.")

        self.data = df.values.flatten()
        np.random.shuffle(self.data)
        self.data_len = len(self.data)

        print(f"Total number of resistance data points: {self.data_len}")

        del df
        gc.collect()

    @staticmethod
    def row_col_bit(a):
        b = math.log2(a)
        x = (b + a) / 2
        y = a - x
        return round(x), round(y)

    @staticmethod
    def get_response(rram_cell_1, rram_cell_2):
        return (rram_cell_1 > rram_cell_2).astype(np.uint8)

    @staticmethod
    def converts_decimal(count, arr):
        arr = np.asarray(arr, dtype=np.uint8)
        powers = (1 << np.arange(len(arr) - 1, -1, -1, dtype=np.uint64))
        return int(np.dot(arr, powers))

    def process_challenge_batch(self, batch_indices, challenge_len, select_line):
        results = []
        data = self.data

        for i in batch_indices:
            a1 = np.random.choice(data, challenge_len, replace=False)
            remaining = np.setdiff1d(data, a1)
            a2 = np.random.choice(remaining, challenge_len, replace=False)

            challenge_bits = np.array(
                list(map(int, np.binary_repr(i, width=challenge_len))),
                dtype=np.uint8
            )
            response_bits = self.get_response(a1, a2)

            results.append((
                ''.join(map(str, challenge_bits)),
                ''.join(map(str, response_bits)),
                self.converts_decimal(challenge_len - 1, challenge_bits),
                self.converts_decimal(challenge_len - 1, response_bits)
            ))

        return results

    def challenge_response_diff(
        self,
        crp,
        challenge_len,
        file_name,
        save_csv=True,
        Binary=True,
        timestamp="",
        run_idx=None,
        print_save_info=False
    ):
        row, _ = self.row_col_bit(challenge_len)
        select_line = row

        num_workers = min(cpu_count(), 8)

        if not timestamp:
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

        folder_name = f"{timestamp}_C{challenge_len}R{crp}"

        base_dir = os.path.dirname(file_name)
        base_filename = os.path.basename(file_name)

        timestamp_dir = os.path.join(base_dir, folder_name)
        csv_dir = os.path.join(timestamp_dir, "CSV")
        txt_dir = os.path.join(timestamp_dir, "txt")

        os.makedirs(csv_dir, exist_ok=True)
        os.makedirs(txt_dir, exist_ok=True)

        # âœ… PRINT SAVE INFO ONLY ONCE
        if print_save_info:
            print("\n\n[SAVE INFO]")
            print("\nBase file name      :", base_filename)
            print("\nBase directory      :", os.path.abspath(base_dir))
            print("\nTimestamp directory :", os.path.abspath(timestamp_dir))
            print("\nCSV save directory  :", os.path.abspath(csv_dir))
            print("\nTXT save directory  :", os.path.abspath(txt_dir))
            print("\n" + "*" * 82+"\n")
            print("                           [PUF RESULT]\n")
            print("                          [END SAVE INFO]")
            print("\n"+"*" * 82 + "\n")

        total_challenges = 2 ** crp
        batch_size = 262200
        num_batches = (total_challenges + batch_size - 1) // batch_size

        with Pool(processes=num_workers) as pool:
            for batch_idx in range(num_batches):
                start = batch_idx * batch_size
                end = min((batch_idx + 1) * batch_size, total_challenges)

                print(f"\nUsing {num_workers} CPU cores...")
                print(f"\nProcessing batch {batch_idx + 1}/{num_batches} ({start}â€“{end - 1})")

                indices = np.array_split(np.arange(start, end), num_workers)
                func = partial(
                    self.process_challenge_batch,
                    challenge_len=challenge_len,
                    select_line=select_line
                )

                results = pool.map(func, indices)
                results = [r for sub in results for r in sub]

                challenges_bin, responses_bin, challenges, responses = zip(*results)

                run_suffix = f"_run{run_idx}" if run_idx is not None else ""

                csv_file = os.path.join(
                    csv_dir,
                    f"{base_filename}_C{challenge_len}R{crp}_batch{batch_idx}{run_suffix}.csv"
                )
                txt_file = os.path.join(
                    txt_dir,
                    f"{base_filename}_C{challenge_len}R{crp}_batch{batch_idx}{run_suffix}.txt"
                )

                if save_csv:
                    pd.DataFrame({
                        f"Challenges_{challenge_len}": challenges_bin,
                        f"ResponsesBinary_{challenge_len}": responses_bin,
                        "ChallengeDecimal": challenges,
                        "ResponseDecimal": responses
                    }).to_csv(csv_file, index=False)

                if Binary:
                    with open(txt_file, "w") as f:
                        f.write("".join(responses_bin))

                print(f"\nSaved batch {batch_idx + 1}{run_suffix}")

                del results
                gc.collect()


def main_HRS(
    challenge_size,
    crp,
    save_csv=True,
    Binary=True,
    runs=10,
    timestamp="",
    project_root=None
):
    base_timestamp = timestamp or datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))

    input_file = os.path.abspath(os.path.join(
        BASE_DIR,
        "..", "..", "..",
        "TRNG_PIYUSH",
        "RRAM_1M_data",
        "1.9V-1us 1million data.csv"
    ))

    print("\n[PATH INFO]")
    print("\nPUFDesign file :", os.path.abspath(__file__))
    print("\nInput CSV file :", input_file)
    print("\nInput exists   :", os.path.exists(input_file))
    print("\n")

    puf = PUFDesign(crp, input_file, usecols=[1], skiprows=[0])

    file_name = os.path.abspath(os.path.join(
        BASE_DIR,
        "..", "..", "..",
        "TRNG_PIYUSH",
        "Result",
        "TRAN_result",
        "TRNG_bitstream_data"
    ))

    for run_idx in range(runs):
        # print("\n[RUN INFO]")


        puf.challenge_response_diff(
            crp,
            challenge_size,
            file_name,
            save_csv=save_csv,
            Binary=Binary,
            timestamp=base_timestamp,
            run_idx=run_idx,
            print_save_info=(run_idx == 0)  # âœ… ONLY FIRST RUN
        )

        print(f"\n[HARN] Run {run_idx + 1}/{runs} with timestamp {base_timestamp}\n")


if __name__ == "__main__":
    try:
        c = input("Enter challenge size (default 16): ").strip()
        r = input("Enter crp (default 8): ").strip()

        main_HRS(
            int(c) if c else 16,
            int(r) if r else 8,
            runs=2
        )

    except EOFError:
        main_HRS(16, 8, runs=2)

    except Exception as e:
        print(f"[ERROR] {e}")
